{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f489e2cb-8ae9-4e86-9494-83ccd3bd8968",
   "metadata": {
    "tags": []
   },
   "source": [
    "# About this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf89e7-3df4-4d22-b4ab-8a65005ddf34",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to import the data from each flight into a single h5 file containing all the flights referenced by key. It also introduce how to convert h5 file to pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6993527-b71d-4569-9dc8-cfaeadc0fae2",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea467d3-2fa9-4496-83ea-eb9bd2eabb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from pyproj import Transformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823a000",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0 - Read Filght Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a94e7",
   "metadata": {},
   "source": [
    "Here we create a function that allows us to read the h5 data in a pandas dataframe from a single flight file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0ac559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_filght_data(flight_number, verbose=False):\n",
    "    \"\"\"\n",
    "    Read h5 flight data and convert it to a pandas dataframe\n",
    "    \n",
    "    Arguments:\n",
    "    - `flight_number` : number of the flight we want to convert to a dataframe\n",
    "    - `verbose` : print keys with NaNs and infos\n",
    "    \n",
    "    Returns:\n",
    "    - `df` : pandas dataframe containing data from the flight\n",
    "    \"\"\"\n",
    "    \n",
    "    # Import h5 flight data\n",
    "    file_path = f'../data/raw/Flt100{flight_number}-train.h5'\n",
    "    flight_data = h5py.File(file_path, 'r')\n",
    "    \n",
    "    # Put flight data in a dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for key in flight_data.keys():                                 \n",
    "        data = flight_data[key]                                          \n",
    "        if data.shape != ():                                             \n",
    "            df[key] = data[:]\n",
    "            if df[key].isnull().any()&verbose:\n",
    "                print(f'{key} contains NaN(s)')\n",
    "        elif verbose:\n",
    "            print(f'{key} = {data[()]}')\n",
    "    \n",
    "    # Rename the column names for flights 6 and 7 to match the column names of the other flights\n",
    "    if flight_number == 7 or 6:\n",
    "        df.rename(columns = {'line':'tie_line','utm_x':'utmX','utm_y':'utmY',\n",
    "                             'utm_z':'utmZ','msl':'alt','ins_yaw':'ins_azim',\n",
    "                             'pitch_rate':'pitch_rt','roll_rate':'roll_rt',\n",
    "                             'yaw_rate':'yaw_rt','lgtl_acc':'lon_acc',\n",
    "                             'ltrl_acc':'lat_acc','nrml_acc':'alt_acc',\n",
    "                             'tas':'true_as','vol_srvo':'vol_servo'},inplace=True)\n",
    "        \n",
    "    # Rename the columns according to the challenge data fields\n",
    "    datafields = pd.read_csv('../data/raw/datafields.csv',\n",
    "                         header=None,\n",
    "                         index_col=0).to_dict()[1]\n",
    "    df = df.rename(columns=datafields,\n",
    "                   errors=\"raise\")\n",
    "\n",
    "    # index by TIME (sort)\n",
    "    df = df.sort_values(by=['TIME'])\n",
    "    df.index = df['TIME']\n",
    "    df.index.name = 'Time [s]'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5b11d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 160030\n",
      "drape contains NaN(s)\n",
      "dt = 0.09611163227016886\n",
      "ogs_alt contains NaN(s)\n",
      "ogs_mag contains NaN(s)\n"
     ]
    }
   ],
   "source": [
    "# Test on flight numner 3\n",
    "flight_number = 3\n",
    "df = read_filght_data(flight_number, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c87a4",
   "metadata": {},
   "source": [
    "\"NOTE: The dt field in each HDF5 file is incorrect. The correct value is 0.1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a535fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUXB_X</th>\n",
       "      <th>FLUXB_Y</th>\n",
       "      <th>FLUXB_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>160030.000000</td>\n",
       "      <td>160030.000000</td>\n",
       "      <td>160030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34805.294581</td>\n",
       "      <td>32631.568086</td>\n",
       "      <td>-8968.910635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10137.198973</td>\n",
       "      <td>8970.374849</td>\n",
       "      <td>13916.578430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-15.877000</td>\n",
       "      <td>-4469.929000</td>\n",
       "      <td>-30561.526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25884.512500</td>\n",
       "      <td>25396.999000</td>\n",
       "      <td>-21958.479750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35410.303000</td>\n",
       "      <td>34002.262000</td>\n",
       "      <td>-10081.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44255.286000</td>\n",
       "      <td>40194.784000</td>\n",
       "      <td>5911.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54512.841000</td>\n",
       "      <td>51630.098000</td>\n",
       "      <td>15810.443000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FLUXB_X        FLUXB_Y        FLUXB_Z\n",
       "count  160030.000000  160030.000000  160030.000000\n",
       "mean    34805.294581   32631.568086   -8968.910635\n",
       "std     10137.198973    8970.374849   13916.578430\n",
       "min       -15.877000   -4469.929000  -30561.526000\n",
       "25%     25884.512500   25396.999000  -21958.479750\n",
       "50%     35410.303000   34002.262000  -10081.293000\n",
       "75%     44255.286000   40194.784000    5911.287000\n",
       "max     54512.841000   51630.098000   15810.443000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the data has been imported\n",
    "df[['FLUXB_X', 'FLUXB_Y', 'FLUXB_Z']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce6cda",
   "metadata": {},
   "source": [
    "Testing for good understanding of geographic conventions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6f319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WGS_to_UTC = Transformer.from_crs(crs_from=4326, # EPSG:4326 World Geodetic System 1984, https://epsg.io/4326\n",
    "                                  crs_to=32618)  # EPSG:32618 WGS 84/UTM zone 18N, https://epsg.io/32618\n",
    "\n",
    "# Transfom (LAT, LONG) -> (X_UTM, Y_UTM)\n",
    "UTM_X_pyproj, UTM_Y_pyproj = WGS_to_UTC.transform(df.LAT.values,\n",
    "                                                  df.LONG.values)\n",
    "\n",
    "# Check if the converted coordinates and the dataset coordinates are equal (+/- 1.4cm).\n",
    "all(np.sqrt((df.UTM_X - UTM_X_pyproj)**2 + (df.UTM_Y - UTM_Y_pyproj)**2) < 0.014)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c5b64",
   "metadata": {},
   "source": [
    "# 1 - Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a4486",
   "metadata": {},
   "source": [
    "The data of the 5 flights are stored in HDF5 files :\n",
    "* Flt1002-train.h5\n",
    "* Flt1003-train.h5\n",
    "* Flt1004-train.h5\n",
    "* Flt1005-train.h5\n",
    "\n",
    "To make data access and readability easier, we group all flights in a single h5 file. In the next cell, we export all flights in a single h5 file named 'Flt_data.h5', we also export flights to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90cae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7f294647cc4c9399c22162ecb5772d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for flight_number in tqdm_notebook(range(2,8)):\n",
    "    df = read_filght_data(flight_number)\n",
    "    \n",
    "    # export to HDF5\n",
    "    df.to_hdf('../data/interim/Flt_data.h5',\n",
    "              key=f'Flt100{flight_number}')\n",
    "    \n",
    "    # export to csv\n",
    "    df.to_csv(f'../data/interim/Flt_data_csv/Flt100{flight_number}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209ddac",
   "metadata": {},
   "source": [
    " Let's check if if the import works properly :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9500768f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_hdf('../data/interim/Flt_data.h5',\n",
    "                  key=f'Flt100{flight_number}')\n",
    "all(df2 == df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
