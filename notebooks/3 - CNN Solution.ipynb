{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787cf624-2022-4398-b171-8966cf5961b1",
   "metadata": {},
   "source": [
    "# About this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290a9f7-eb43-4303-b2ed-1b86764c3c69",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to study a convolutional network solution. The MLP performs well when the validation/test is on the same flight as the training, however it does not generalize well to other flights. We will therefore try to use a new architecture able to detect more complex pattern in the data : a convolutional network. See previous notebook for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9cba1-7aeb-4a82-9186-739d60dbd969",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4568c7-dc1c-4e4c-ba08-405f6421d611",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ed86a52-9f7d-405e-a43d-c517ec78c40a",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4daf1ac5-b32c-4443-8431-a92261cfe72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import random\n",
    "import magnav\n",
    "import os\n",
    "from ipywidgets import widgets\n",
    "from torchinfo import summary\n",
    "import ast\n",
    "from matplotlib.collections import LineCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4622fc2d-f240-43f0-9af6-505aac39de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "torch.manual_seed(27)\n",
    "random.seed(27)\n",
    "np.random.seed(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15ba8b-e75a-4587-9937-0cc6da51ed6b",
   "metadata": {},
   "source": [
    "# 1 - What is a Convolutional Neural Network <a class=\"anchor\" id = \"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408120d8-67e7-42d1-87fb-22c7d32b277b",
   "metadata": {},
   "source": [
    "A convolutional neural network (CNN, or ConvNet) is a class of artificial neural network (ANN), most commonly applied to analyze visual imagery. Convolutional neural network are a specialized type of artificial neural networks that use a mathematical operation called convolution in place of general matrix multiplication in at least one of their layers. CNN are often compared to the way the brain achieves vision processing in living organisms.\n",
    "\n",
    "Typical architecture of a convolutional neural network:\n",
    "\n",
    "<img src=\"../data/external/Images/CNN.jpeg\" alt=\"CNN\" width=\"700\"/>\n",
    "\n",
    "A convolutional neural network consits of an input layer, hidden layers and an output layer. In a CNN, the hidden layers include layers that perform convolutions. Typically this includes a layer that performs a dot product of the convolution kernel with the layer's input matrix. This product is usually the [Frobenius inner product](https://en.wikipedia.org/wiki/Frobenius_inner_product), and its activattion function is commonly [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks). As the convolution kernel slides along the input matrix for the layer, the convolution operation generates a feature map, which in turn contributes to the input of the next layer. This is followed by other layers such as pooling layers, fully connected layers, and normalization layers.\n",
    "\n",
    "<font size='3'><b>Convolutional layers</b></font>\n",
    "\n",
    "Convolutional layer convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus. After passing through a convolutional layer, the image becomes abstracted to a feature map, also called an activation map :\n",
    "\n",
    "<img src=\"../data/external/Images/2D_Convolution_Animation.gif\" alt=\"CNN\" width=\"300\"/>\n",
    "\n",
    "<font size='3'><b>Pooling layers</b></font>\n",
    "\n",
    "Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, tilling sizes such as 2x2 are commonly used. Global pooling acts on all the neurons of the feature map. There are two common types of pooling in popular use :\n",
    "- Max pooling uses the maximum value of each local cluster of neurons in the feature map\n",
    "- Average pooling takes the average value of each local cluster of neurons in the feature map\n",
    "\n",
    "Here is an expemple of Max Pooling :\n",
    "\n",
    "<img src=\"../data/external/Images/Max_Pooling_GIFg.gif\" alt=\"CNN\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9bf97-049b-4e41-98ca-38e0edf101d8",
   "metadata": {},
   "source": [
    "## Specifity of time-series data for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734be54-c42b-4071-a2a2-1e15c64e6780",
   "metadata": {},
   "source": [
    "In our case we have *multivariate* time series data. This mean that there is more than one observation for each time step. We are trying to create a model able to use a sequence of multiple input series and output one time series dependant on the input time series. The input time series are parallel because each series has observations at the same time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb43ecb-d406-412b-8597-f9f0db345d8a",
   "metadata": {},
   "source": [
    "# 2 - Import of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00882998-7e48-4fdf-976f-48b2f77fb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_hdf('../data/interim/Chall_dataset.h5', key=f'Flt1002')\n",
    "df3 = pd.read_hdf('../data/interim/Chall_dataset.h5', key=f'Flt1003')\n",
    "df4 = pd.read_hdf('../data/interim/Chall_dataset.h5', key=f'Flt1004')\n",
    "df5 = pd.read_hdf('../data/interim/Chall_dataset.h5', key=f'Flt1005')\n",
    "df6 = pd.read_hdf('../data/interim/Chall_dataset.h5', key=f'Flt1006')\n",
    "df7 = pd.read_hdf('../data/interim/Chall_dataset.h5', key=f'Flt1007')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f67c79-c6e3-4f0e-98f1-3c71ef579aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL_comp_mag3_cl</th>\n",
       "      <th>TL_comp_mag5_cl</th>\n",
       "      <th>V_BAT1</th>\n",
       "      <th>V_BAT2</th>\n",
       "      <th>INS_ACC_X</th>\n",
       "      <th>INS_ACC_Y</th>\n",
       "      <th>INS_ACC_Z</th>\n",
       "      <th>CUR_IHTR</th>\n",
       "      <th>PITCH</th>\n",
       "      <th>ROLL</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>LINE</th>\n",
       "      <th>IGRFMAG1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time [s]</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45100.0</th>\n",
       "      <td>-1026.777805</td>\n",
       "      <td>-44.982774</td>\n",
       "      <td>25.827</td>\n",
       "      <td>2.015</td>\n",
       "      <td>-0.109544</td>\n",
       "      <td>-0.389939</td>\n",
       "      <td>9.353474</td>\n",
       "      <td>1.734</td>\n",
       "      <td>9.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>204.01</td>\n",
       "      <td>1002.01</td>\n",
       "      <td>-297.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45100.1</th>\n",
       "      <td>-1023.030351</td>\n",
       "      <td>-40.600326</td>\n",
       "      <td>25.826</td>\n",
       "      <td>2.014</td>\n",
       "      <td>-0.157305</td>\n",
       "      <td>-0.441169</td>\n",
       "      <td>9.317263</td>\n",
       "      <td>1.759</td>\n",
       "      <td>9.08</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>203.95</td>\n",
       "      <td>1002.01</td>\n",
       "      <td>-296.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45100.2</th>\n",
       "      <td>-1021.286230</td>\n",
       "      <td>-34.817623</td>\n",
       "      <td>25.824</td>\n",
       "      <td>2.013</td>\n",
       "      <td>-0.179486</td>\n",
       "      <td>-0.462637</td>\n",
       "      <td>9.348927</td>\n",
       "      <td>1.783</td>\n",
       "      <td>8.96</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>203.91</td>\n",
       "      <td>1002.01</td>\n",
       "      <td>-295.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45100.3</th>\n",
       "      <td>-1023.965085</td>\n",
       "      <td>-29.347438</td>\n",
       "      <td>25.820</td>\n",
       "      <td>2.010</td>\n",
       "      <td>-0.208515</td>\n",
       "      <td>-0.496153</td>\n",
       "      <td>9.333830</td>\n",
       "      <td>1.796</td>\n",
       "      <td>8.85</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>203.90</td>\n",
       "      <td>1002.01</td>\n",
       "      <td>-293.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45100.4</th>\n",
       "      <td>-1030.701663</td>\n",
       "      <td>-25.421394</td>\n",
       "      <td>25.815</td>\n",
       "      <td>2.007</td>\n",
       "      <td>-0.252133</td>\n",
       "      <td>-0.507891</td>\n",
       "      <td>9.261835</td>\n",
       "      <td>1.788</td>\n",
       "      <td>8.73</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>203.91</td>\n",
       "      <td>1002.01</td>\n",
       "      <td>-292.821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TL_comp_mag3_cl  TL_comp_mag5_cl  V_BAT1  V_BAT2  INS_ACC_X  \\\n",
       "Time [s]                                                                \n",
       "45100.0      -1026.777805       -44.982774  25.827   2.015  -0.109544   \n",
       "45100.1      -1023.030351       -40.600326  25.826   2.014  -0.157305   \n",
       "45100.2      -1021.286230       -34.817623  25.824   2.013  -0.179486   \n",
       "45100.3      -1023.965085       -29.347438  25.820   2.010  -0.208515   \n",
       "45100.4      -1030.701663       -25.421394  25.815   2.007  -0.252133   \n",
       "\n",
       "          INS_ACC_Y  INS_ACC_Z  CUR_IHTR  PITCH  ROLL  AZIMUTH     LINE  \\\n",
       "Time [s]                                                                  \n",
       "45100.0   -0.389939   9.353474     1.734   9.19  0.19   204.01  1002.01   \n",
       "45100.1   -0.441169   9.317263     1.759   9.08 -0.03   203.95  1002.01   \n",
       "45100.2   -0.462637   9.348927     1.783   8.96 -0.22   203.91  1002.01   \n",
       "45100.3   -0.496153   9.333830     1.796   8.85 -0.39   203.90  1002.01   \n",
       "45100.4   -0.507891   9.261835     1.788   8.73 -0.55   203.91  1002.01   \n",
       "\n",
       "          IGRFMAG1  \n",
       "Time [s]            \n",
       "45100.0   -297.343  \n",
       "45100.1   -296.223  \n",
       "45100.2   -295.079  \n",
       "45100.3   -293.939  \n",
       "45100.4   -292.821  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9581600-b402-40f2-bb4a-e49d174874c9",
   "metadata": {},
   "source": [
    "# 3 - Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1090131-5c98-4736-8f87-85cc4a14cdcd",
   "metadata": {},
   "source": [
    "## 3.1 - MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058ab94d-49fb-4faa-9cb1-b8b6f988b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL_comp_mag3_cl</th>\n",
       "      <th>TL_comp_mag5_cl</th>\n",
       "      <th>V_BAT1</th>\n",
       "      <th>V_BAT2</th>\n",
       "      <th>INS_ACC_X</th>\n",
       "      <th>INS_ACC_Y</th>\n",
       "      <th>INS_ACC_Z</th>\n",
       "      <th>CUR_IHTR</th>\n",
       "      <th>PITCH</th>\n",
       "      <th>ROLL</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>LINE</th>\n",
       "      <th>IGRFMAG1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "      <td>207578.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.120479</td>\n",
       "      <td>-0.499555</td>\n",
       "      <td>-0.643363</td>\n",
       "      <td>-0.078342</td>\n",
       "      <td>-0.124208</td>\n",
       "      <td>-0.031765</td>\n",
       "      <td>0.058171</td>\n",
       "      <td>-0.026525</td>\n",
       "      <td>0.202881</td>\n",
       "      <td>-0.090270</td>\n",
       "      <td>0.105508</td>\n",
       "      <td>1152.355312</td>\n",
       "      <td>15.822918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.060556</td>\n",
       "      <td>0.148419</td>\n",
       "      <td>0.223182</td>\n",
       "      <td>0.484986</td>\n",
       "      <td>0.168563</td>\n",
       "      <td>0.163822</td>\n",
       "      <td>0.109107</td>\n",
       "      <td>0.352792</td>\n",
       "      <td>0.232093</td>\n",
       "      <td>0.257489</td>\n",
       "      <td>0.537493</td>\n",
       "      <td>603.633030</td>\n",
       "      <td>263.641503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>-868.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.092208</td>\n",
       "      <td>-0.566069</td>\n",
       "      <td>-0.749049</td>\n",
       "      <td>-0.471795</td>\n",
       "      <td>-0.174118</td>\n",
       "      <td>-0.076751</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>-0.260143</td>\n",
       "      <td>0.078834</td>\n",
       "      <td>-0.167997</td>\n",
       "      <td>-0.246764</td>\n",
       "      <td>1002.030000</td>\n",
       "      <td>-106.787250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.119767</td>\n",
       "      <td>-0.498298</td>\n",
       "      <td>-0.673004</td>\n",
       "      <td>-0.298462</td>\n",
       "      <td>-0.122392</td>\n",
       "      <td>-0.031005</td>\n",
       "      <td>0.058330</td>\n",
       "      <td>-0.072517</td>\n",
       "      <td>0.188985</td>\n",
       "      <td>-0.101912</td>\n",
       "      <td>0.016722</td>\n",
       "      <td>1002.150000</td>\n",
       "      <td>24.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.149140</td>\n",
       "      <td>-0.444462</td>\n",
       "      <td>-0.596958</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>-0.071264</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.103938</td>\n",
       "      <td>0.166514</td>\n",
       "      <td>0.307775</td>\n",
       "      <td>-0.032857</td>\n",
       "      <td>0.608167</td>\n",
       "      <td>1002.200000</td>\n",
       "      <td>120.868500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3086.000000</td>\n",
       "      <td>2699.331000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TL_comp_mag3_cl  TL_comp_mag5_cl         V_BAT1         V_BAT2  \\\n",
       "count    207578.000000    207578.000000  207578.000000  207578.000000   \n",
       "mean          0.120479        -0.499555      -0.643363      -0.078342   \n",
       "std           0.060556         0.148419       0.223182       0.484986   \n",
       "min          -1.000000        -1.000000      -1.000000      -1.000000   \n",
       "25%           0.092208        -0.566069      -0.749049      -0.471795   \n",
       "50%           0.119767        -0.498298      -0.673004      -0.298462   \n",
       "75%           0.149140        -0.444462      -0.596958       0.360000   \n",
       "max           1.000000         1.000000       1.000000       1.000000   \n",
       "\n",
       "           INS_ACC_X      INS_ACC_Y      INS_ACC_Z       CUR_IHTR  \\\n",
       "count  207578.000000  207578.000000  207578.000000  207578.000000   \n",
       "mean       -0.124208      -0.031765       0.058171      -0.026525   \n",
       "std         0.168563       0.163822       0.109107       0.352792   \n",
       "min        -1.000000      -1.000000      -1.000000      -1.000000   \n",
       "25%        -0.174118      -0.076751       0.013592      -0.260143   \n",
       "50%        -0.122392      -0.031005       0.058330      -0.072517   \n",
       "75%        -0.071264       0.014450       0.103938       0.166514   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               PITCH           ROLL        AZIMUTH           LINE  \\\n",
       "count  207578.000000  207578.000000  207578.000000  207578.000000   \n",
       "mean        0.202881      -0.090270       0.105508    1152.355312   \n",
       "std         0.232093       0.257489       0.537493     603.633030   \n",
       "min        -1.000000      -1.000000      -1.000000     158.000000   \n",
       "25%         0.078834      -0.167997      -0.246764    1002.030000   \n",
       "50%         0.188985      -0.101912       0.016722    1002.150000   \n",
       "75%         0.307775      -0.032857       0.608167    1002.200000   \n",
       "max         1.000000       1.000000       1.000000    3086.000000   \n",
       "\n",
       "            IGRFMAG1  \n",
       "count  207578.000000  \n",
       "mean       15.822918  \n",
       "std       263.641503  \n",
       "min      -868.652000  \n",
       "25%      -106.787250  \n",
       "50%        24.219500  \n",
       "75%       120.868500  \n",
       "max      2699.331000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()\n",
    "\n",
    "scaling_range = [-1,1]\n",
    "MinMaxScaler_2 = MinMaxScaler(scaling_range)\n",
    "MinMaxScaler_3 = MinMaxScaler(scaling_range)\n",
    "MinMaxScaler_4 = MinMaxScaler(scaling_range)\n",
    "MinMaxScaler_7 = MinMaxScaler(scaling_range)\n",
    "\n",
    "\n",
    "df2_scaled = pd.DataFrame()\n",
    "df3_scaled = pd.DataFrame()\n",
    "df4_scaled = pd.DataFrame()\n",
    "df7_scaled = pd.DataFrame()\n",
    "\n",
    "\n",
    "df2_scaled[df2.drop(columns=['LINE','IGRFMAG1']).columns] = MinMaxScaler_2.fit_transform(df2.drop(columns=['LINE','IGRFMAG1']))\n",
    "df3_scaled[df3.drop(columns=['LINE','IGRFMAG1']).columns] = MinMaxScaler_3.fit_transform(df3.drop(columns=['LINE','IGRFMAG1']))\n",
    "df4_scaled[df4.drop(columns=['LINE','IGRFMAG1']).columns] = MinMaxScaler_4.fit_transform(df4.drop(columns=['LINE','IGRFMAG1']))\n",
    "df7_scaled[df4.drop(columns=['LINE','IGRFMAG1']).columns] = MinMaxScaler_7.fit_transform(df7.drop(columns=['LINE','IGRFMAG1']))\n",
    "\n",
    "\n",
    "df2_scaled.index = df2.index\n",
    "df3_scaled.index = df3.index\n",
    "df4_scaled.index = df4.index\n",
    "df7_scaled.index = df7.index\n",
    "\n",
    "\n",
    "df2_scaled[['LINE','IGRFMAG1']] = df2[['LINE','IGRFMAG1']]\n",
    "df3_scaled[['LINE','IGRFMAG1']] = df3[['LINE','IGRFMAG1']]\n",
    "df4_scaled[['LINE','IGRFMAG1']] = df4[['LINE','IGRFMAG1']]\n",
    "df7_scaled[['LINE','IGRFMAG1']] = df7[['LINE','IGRFMAG1']]\n",
    "\n",
    "\n",
    "df2_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccef04-8f60-4ded-a0c7-b54e14aa5b8c",
   "metadata": {},
   "source": [
    "## 3.2 - Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff7a42-6019-4a11-a66d-2979804acfdc",
   "metadata": {},
   "source": [
    "# 4 - Input Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2e26e-d6a6-47e5-843a-345d2de2aad5",
   "metadata": {},
   "source": [
    "Unlike the MLP, we will enter the data in sequence form :\n",
    "\n",
    "$ \n",
    "\\begin{matrix}\n",
    "&\n",
    "\\begin{bmatrix}\n",
    "t_0 & t_1 & t_2 & t_3 & \\ldots & t_n\n",
    "\\end{bmatrix} \n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "feature\\,1 \\\\\n",
    "feature\\,2 \\\\\n",
    "\\vdots \\\\\n",
    "feature\\,k\n",
    "\\end{bmatrix} \n",
    "&\n",
    "\\begin{bmatrix}\n",
    "f_{11} & f_{12} & f_{13} & \\ldots & f_{1n} \\\\\n",
    "f_{21} & f_{22} & f_{23} & \\ldots & f_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "f_{k1} & f_{k2} & f_{k3} & \\ldots & f_{kn} \n",
    "\\end{bmatrix}\n",
    "\\\\\n",
    "\\begin{bmatrix}\n",
    "truth\n",
    "\\end{bmatrix} \n",
    "&\n",
    "\\begin{bmatrix}\n",
    "&\\quad\n",
    "&\\quad\n",
    "&\\quad\n",
    "&\\quad\n",
    "&\n",
    "y_{n}\n",
    "\\end{bmatrix}\n",
    "\\end{matrix}\n",
    "$\n",
    "\n",
    "\n",
    "To ensure that only whole sequences will be given to the model, we use the function below to remove the last data that does not fit in a sequence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d717da54-f152-4959-bf73-9a2ad9b38c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_data(data,seq_length):\n",
    "    # Remove excessive data that cannot be in a full sequence\n",
    "    if (len(data)%seq_length) != 0:\n",
    "        data = data[:-(len(data)%seq_length)]\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f578336a-6772-4b71-bd79-a252118a7225",
   "metadata": {},
   "source": [
    "The function below is used to create the dataset and send the data as a sequence to the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ef6ed4-bbe8-45dc-96a5-596d982e47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagNavDataset(Dataset):\n",
    "    # split can be 'Train', 'Val', 'Test'\n",
    "    def __init__(self, df, seq_length, split):\n",
    "        \n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # Get list of features\n",
    "        self.features   = df.drop(columns=['LINE','IGRFMAG1']).columns.to_list()\n",
    "        \n",
    "        if split == 'train':\n",
    "            \n",
    "            # Keeping only 1003, 1002 and 1004 flight sections for training except 1002.14\n",
    "            sections = np.concatenate([df2.LINE.unique(),df3.LINE.unique(),df4.LINE.unique()]).tolist()\n",
    "            sections.remove(1002.14)\n",
    "            self.sections = sections\n",
    "            mask_train = pd.Series(dtype=bool)\n",
    "            for line in sections:\n",
    "                mask  = (df.LINE == line)\n",
    "                mask_train = mask|mask_train\n",
    "            \n",
    "            # Split in X, y for training\n",
    "            X_train    = df.loc[mask_train,self.features]\n",
    "            y_train    = df.loc[mask_train,'IGRFMAG1']\n",
    "            \n",
    "            # Removing data that can't fit in full sequence and convert it to torch tensor\n",
    "            self.X = torch.t(trim_data(torch.tensor(X_train.to_numpy(),dtype=torch.float32),seq_length))\n",
    "            self.y = trim_data(torch.tensor(np.reshape(y_train.to_numpy(),[-1,1]),dtype=torch.float32),seq_length)\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif split == 'val':\n",
    "            \n",
    "            # Selecting 1002.14 for validation\n",
    "            mask_val   = (df.LINE == 1002.14)\n",
    "            self.sections = 1002.14\n",
    "            \n",
    "            # Split in X, y for validation\n",
    "            X_val      = df.loc[mask_val,self.features]\n",
    "            y_val      = df.loc[mask_val,'IGRFMAG1']\n",
    "            \n",
    "            # Removing data that can't fit in full sequence and convert it to torch tensor\n",
    "            self.X = torch.t(trim_data(torch.tensor(X_val.to_numpy(),dtype=torch.float32),seq_length))\n",
    "            self.y = trim_data(torch.tensor(np.reshape(y_val.to_numpy(),[-1,1]),dtype=torch.float32),seq_length)\n",
    "            \n",
    "        elif split == 'test':\n",
    "            \n",
    "            # Slecting flight 1007 as test\n",
    "            mask_test = pd.Series(dtype=bool)\n",
    "            for line in [1007.06]:#df6.LINE.unique():\n",
    "                mask  = (df.LINE == line)\n",
    "                mask_test = mask|mask_test\n",
    "            \n",
    "            # Split in X, y for test\n",
    "            X_test     = df.loc[mask_test,self.features]\n",
    "            y_test     = df.loc[mask_test,'IGRFMAG1']\n",
    "            \n",
    "            # Removing data that can't fit in full sequence and convert it to torch tensor\n",
    "            self.X = torch.t(trim_data(torch.tensor(X_test.to_numpy(),dtype=torch.float32),seq_length))\n",
    "            self.y = trim_data(torch.tensor(np.reshape(y_test.to_numpy(),[-1,1]),dtype=torch.float32),seq_length)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[:,index:(index+self.seq_length)]\n",
    "        y = self.y[index+self.seq_length-1]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(torch.t(self.X))-self.seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f186dcc-b83c-4dd3-8228-160ed77648af",
   "metadata": {},
   "source": [
    "# 5 - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b617b5-33e1-4b97-9f13-408597f82476",
   "metadata": {},
   "source": [
    "We have seen in a previous [section](#1) what a CNN is. CNNs are mainly used in the field of computer vision, but they can also be used for time-series. CNNs are highly noise-resitant and are also able to extract very informative deep features, which are independent from time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac7c93-a8e5-494d-b62c-025efc8df04c",
   "metadata": {},
   "source": [
    "## 5.1 - Differences between 2D CNN and 1D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7becb1-84a1-4ba2-99e8-43ec659bda57",
   "metadata": {},
   "source": [
    "Contrary to a 2D convolution which moves on 2 dimensions, the 1D convolution moves along the time axis with a width corresponding to the number of signals in input in the case of a multivariate time-series. This means that in output of a 1D convolution, the feature maps are  vectors, while for 2D convolutions they are matrices :\n",
    "\n",
    "<img src=\"../data/external/Images/conv1d.gif\" alt=\"CNN1D\" width=\"700\"/>\n",
    "\n",
    "Conv1D has several advantages over Conv2D for time-series such as smoothing the data or converting a multivariate to univriate problem that better adapt to classical regression algorithms.<br>\n",
    "To get better performances the training is done in the terminal. Here are the steps to follow to train a CNN:\n",
    "\n",
    "<img src=\"../data/external/Images/train_CNN.png\" alt=\"CNN1D\" width=\"700\"/>\n",
    "\n",
    "Be sure to be at the root of the MagNav folder before running the commands. There are multiples parameters available, type ```--help``` after ```./src/models/train_CNN.py``` to see more informations. Note that if you want to change the architecture of the CNN you have to directly modify the ```train_CNN.py```. All trained models are saved in ```models/CNN_runs```. The name correspond to the date when the training finished. Then in the notebook we load the saved model to test it. We below instantiate the CNN class to be able to use our saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb05def-b95a-436f-8ca8-9edd20f0d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.architecture(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557b5c3-1296-4d3c-9647-718da8d57411",
   "metadata": {},
   "source": [
    "# 6 - Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38af23f9-66ca-4af4-9e0f-c0e6026f6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfiles(dirpath):\n",
    "    a = [s for s in os.listdir(dirpath)\n",
    "         if os.path.isfile(os.path.join(dirpath, s))]\n",
    "    a.sort(key=lambda s: os.path.getmtime(os.path.join(dirpath, s)))\n",
    "    return a\n",
    "\n",
    "def getdirs(dirpath):\n",
    "    a = [s for s in os.listdir(dirpath)\n",
    "         if os.path.isdir(os.path.join(dirpath, s))]\n",
    "    a.sort(key=lambda s: os.path.getmtime(os.path.join(dirpath, s)),reverse=True)\n",
    "    return a\n",
    "\n",
    "def getmodel_params(folder_name):\n",
    "    my_file = open(f'../models/CNN_runs/{folder_name}/parameters.txt','r')\n",
    "\n",
    "    content = my_file.readlines()\n",
    "    content = [x.rstrip() for x in content]\n",
    "    content = list(filter(None, content))\n",
    "\n",
    "    for i,item in enumerate(content):\n",
    "        if item == 'Epochs :':\n",
    "            epochs = int(content[i+1])\n",
    "        if item == 'Batch_size :':\n",
    "            batch_size = int(content[i+1])\n",
    "        if item == 'Loss :':\n",
    "            loss = content[i+1][:-2]\n",
    "        if item == 'Scaling :':\n",
    "            scaling = content[i+1]\n",
    "        if item == 'Sequence_length :':\n",
    "            seq_len = int(content[i+1])\n",
    "        if item == 'Training_device :':\n",
    "            device = content[i+1]\n",
    "        if item == 'Execution_time :':\n",
    "            exec_time = int(float(content[i+1][:-1]))\n",
    "        if item == 'Input_shape :':\n",
    "            input_shape = ast.literal_eval(content[i+1])\n",
    "        if item == 'Features :':\n",
    "            features = ast.literal_eval(content[i+1])\n",
    "    \n",
    "    return epochs, batch_size, loss, scaling, seq_len, device, exec_time, input_shape, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4390d5d-6ad3-4d1a-ab20-dc5c0fca78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_summary(models_folder):\n",
    "    folders = getdirs(models_folder)\n",
    "    \n",
    "    table = pd.DataFrame()\n",
    "    \n",
    "    for folder in folders:\n",
    "        \n",
    "        epochs, batch_size, loss, scaling, seq_len, device, exec_time, input_shape, features = getmodel_params(folder)\n",
    "        \n",
    "        my_file = open(f'../models/CNN_runs/{folder}/val_loss.txt','r')\n",
    "        val_loss = my_file.readlines()\n",
    "        val_loss = [float(x.rstrip()) for x in val_loss]\n",
    "        \n",
    "        temp = pd.DataFrame([[folder,min(val_loss),batch_size,seq_len]],columns=['Model number','Best Validation RMSE','Batch size','Sequence size'])\n",
    "        \n",
    "        table = pd.concat([table,temp])\n",
    "    \n",
    "    table = table.reset_index(drop=True)\n",
    "    \n",
    "    return table\n",
    "    \n",
    "    \n",
    "models_summary = models_summary('../models/CNN_runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786bfb08-e59e-42b5-8dbc-53c0a7afb098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model number</th>\n",
       "      <th>Best Validation RMSE</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Sequence size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>CNN_220623_2356</td>\n",
       "      <td>6.701367</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>CNN_220626_2235</td>\n",
       "      <td>6.714774</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>CNN_220624_2330</td>\n",
       "      <td>6.927098</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>CNN_220627_0602</td>\n",
       "      <td>6.944742</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>CNN_220625_1213</td>\n",
       "      <td>6.980413</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>CNN_220626_1707</td>\n",
       "      <td>7.038318</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>CNN_220627_0045</td>\n",
       "      <td>7.068888</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>CNN_220624_0930</td>\n",
       "      <td>7.092378</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>CNN_220627_0820</td>\n",
       "      <td>7.133365</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>CNN_220626_2036</td>\n",
       "      <td>7.171991</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>CNN_220624_0439</td>\n",
       "      <td>7.211748</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>CNN_220625_2034</td>\n",
       "      <td>7.221257</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>CNN_220624_0620</td>\n",
       "      <td>7.276676</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>CNN_220625_0608</td>\n",
       "      <td>7.333573</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>CNN_220626_1227</td>\n",
       "      <td>7.337619</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CNN_220628_001910</td>\n",
       "      <td>7.378581</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>CNN_220624_0412</td>\n",
       "      <td>7.420800</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>CNN_220624_0511</td>\n",
       "      <td>7.476360</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>CNN_220626_0347</td>\n",
       "      <td>7.487698</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>CNN_220626_0756</td>\n",
       "      <td>7.563443</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>CNN_220625_1909</td>\n",
       "      <td>7.661892</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>CNN_220624_1144</td>\n",
       "      <td>7.664004</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>CNN_220623_2039</td>\n",
       "      <td>7.671976</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>CNN_220625_1813</td>\n",
       "      <td>7.694123</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>CNN_220623_2217</td>\n",
       "      <td>7.714494</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>CNN_220625_0305</td>\n",
       "      <td>7.750720</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CNN_220627_155322</td>\n",
       "      <td>7.776463</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>CNN_220624_0415</td>\n",
       "      <td>7.779620</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>CNN_220626_0621</td>\n",
       "      <td>7.782743</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>CNN_220625_1112</td>\n",
       "      <td>7.800733</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>CNN_220624_1030</td>\n",
       "      <td>7.836002</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CNN_220627_163724</td>\n",
       "      <td>7.837065</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CNN_220627_185556</td>\n",
       "      <td>7.850880</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>CNN_220623_1747</td>\n",
       "      <td>7.857606</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>CNN_220627_182402</td>\n",
       "      <td>7.861761</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CNN_220626_1841</td>\n",
       "      <td>7.865022</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>CNN_220627_200253</td>\n",
       "      <td>7.876516</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>CNN_220625_1321</td>\n",
       "      <td>7.889109</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>CNN_220626_0432</td>\n",
       "      <td>7.907585</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>CNN_220625_1523</td>\n",
       "      <td>7.922854</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>CNN_220625_1955</td>\n",
       "      <td>7.925254</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>CNN_220625_1603</td>\n",
       "      <td>7.955680</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>CNN_220625_1255</td>\n",
       "      <td>7.982995</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>CNN_220626_2142</td>\n",
       "      <td>7.990391</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CNN_220628_015805</td>\n",
       "      <td>7.992422</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>CNN_220625_1750</td>\n",
       "      <td>8.004768</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>CNN_220627_125922</td>\n",
       "      <td>8.008395</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>CNN_220623_2224</td>\n",
       "      <td>8.043383</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>CNN_220624_2347</td>\n",
       "      <td>8.046639</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>CNN_220625_0907</td>\n",
       "      <td>8.065196</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model number  Best Validation RMSE  Batch size  Sequence size\n",
       "548    CNN_220623_2356              6.701367          16              5\n",
       "152    CNN_220626_2235              6.714774          16             15\n",
       "378    CNN_220624_2330              6.927098          16             10\n",
       "137    CNN_220627_0602              6.944742          16             15\n",
       "329    CNN_220625_1213              6.980413          16             10\n",
       "165    CNN_220626_1707              7.038318          16             15\n",
       "147    CNN_220627_0045              7.068888          16             15\n",
       "485    CNN_220624_0930              7.092378          16              5\n",
       "132    CNN_220627_0820              7.133365          16             15\n",
       "157    CNN_220626_2036              7.171991          16             15\n",
       "512    CNN_220624_0439              7.211748          64             15\n",
       "246    CNN_220625_2034              7.221257          16             10\n",
       "500    CNN_220624_0620              7.276676          16              5\n",
       "352    CNN_220625_0608              7.333573          16             10\n",
       "178    CNN_220626_1227              7.337619          16             15\n",
       "46   CNN_220628_001910              7.378581          32             50\n",
       "517    CNN_220624_0412              7.420800          64             15\n",
       "508    CNN_220624_0511              7.476360          64             15\n",
       "209    CNN_220626_0347              7.487698          16             10\n",
       "193    CNN_220626_0756              7.563443          16             10\n",
       "258    CNN_220625_1909              7.661892          64             30\n",
       "465    CNN_220624_1144              7.664004          64             15\n",
       "575    CNN_220623_2039              7.671976          16              5\n",
       "267    CNN_220625_1813              7.694123          16             10\n",
       "561    CNN_220623_2217              7.714494          16              5\n",
       "362    CNN_220625_0305              7.750720          64             20\n",
       "99   CNN_220627_155322              7.776463          32             15\n",
       "515    CNN_220624_0415              7.779620          16              5\n",
       "198    CNN_220626_0621              7.782743          64             50\n",
       "336    CNN_220625_1112              7.800733          64             20\n",
       "477    CNN_220624_1030              7.836002          64             15\n",
       "94   CNN_220627_163724              7.837065          32             15\n",
       "79   CNN_220627_185556              7.850880          32             20\n",
       "604    CNN_220623_1747              7.857606          64              5\n",
       "82   CNN_220627_182402              7.861761          32             20\n",
       "161    CNN_220626_1841              7.865022          64            100\n",
       "72   CNN_220627_200253              7.876516          32             30\n",
       "316    CNN_220625_1321              7.889109          64             30\n",
       "205    CNN_220626_0432              7.907585          64             50\n",
       "295    CNN_220625_1523              7.922854          64             30\n",
       "253    CNN_220625_1955              7.925254          64             30\n",
       "287    CNN_220625_1603              7.955680          16             10\n",
       "321    CNN_220625_1255              7.982995          64             30\n",
       "155    CNN_220626_2142              7.990391          64            100\n",
       "35   CNN_220628_015805              7.992422          32            100\n",
       "272    CNN_220625_1750              8.004768          64             30\n",
       "119  CNN_220627_125922              8.008395          32              5\n",
       "560    CNN_220623_2224              8.043383          64             10\n",
       "377    CNN_220624_2347              8.046639          64             20\n",
       "343    CNN_220625_0907              8.065196          64             20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_summary.sort_values(by=['Best Validation RMSE']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4221277b-96b7-4e55-bec9-92e3dcd20bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df2,df3,df4,df7],ignore_index=True,axis=0)\n",
    "\n",
    "seq_length = 100\n",
    "\n",
    "train = MagNavDataset(df_concat,seq_length=seq_length,split='train')\n",
    "val   = MagNavDataset(df_concat,seq_length=seq_length,split='val')\n",
    "test  = MagNavDataset(df_concat,seq_length=seq_length,split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86490264-ac23-4fb9-b3a1-0e7b5fc2ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SNR(truth_mag,pred_mag):\n",
    "    \n",
    "    error = pred_mag - truth_mag\n",
    "    std_truth = np.std(truth_mag)\n",
    "    std_error = np.std(error)\n",
    "    \n",
    "    SNR = std_truth / std_error\n",
    "    \n",
    "    return SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "faba4279-0e75-4789-a418-ceeba730ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a widget to select the model folder\n",
    "\n",
    "def visualize_model(model_folder):\n",
    "    \n",
    "    # Load model\n",
    "    model = torch.load(f'../models/CNN_runs/{model_folder}/CNN.pt')\n",
    "    \n",
    "    # Get parameters\n",
    "    epochs, batch_size, loss, scaling, seq_len, device, exec_time, input_shape, features = getmodel_params(model_folder)\n",
    "    \n",
    "    # Make predictions for test data\n",
    "    test  = MagNavDataset(df7,seq_length=seq_len,split='test')\n",
    "    test_loader    = DataLoader(test,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=False,\n",
    "                           num_workers=0,\n",
    "                           pin_memory=False)\n",
    "    preds = []\n",
    "    \n",
    "    for batch_index, (inputs, labels) in enumerate(test_loader):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds.append(model(inputs.to(device)).cpu())\n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    # Compute RMSE\n",
    "    RMSE = magnav.rmse(preds,test.y[seq_len:],False)\n",
    "    SNR  = compute_SNR(test.y[seq_len:].numpy(),preds)\n",
    "    \n",
    "    # Display model summary\n",
    "    print('\\n\\033[4mModel info :\\033[0m\\n')\n",
    "    print(summary(model,input_size=(1,input_shape[0],input_shape[1]),\n",
    "                  col_names=[\"kernel_size\",\"input_size\",\"output_size\",\"num_params\"],\n",
    "                  ))\n",
    "    \n",
    "    # Display training info\n",
    "    print('\\n\\033[4mTraining parameters :\\033[0m\\n')\n",
    "    table = [['Epochs',epochs],\n",
    "             ['Batch Size',batch_size],\n",
    "             ['Loss function',loss],\n",
    "             ['Data scaling',scaling],\n",
    "             ['Input shape',input_shape],\n",
    "             ['Sequence length', seq_len],\n",
    "             ['Training time',magnav.to_hms(exec_time)],\n",
    "             ['Training device',device]]\n",
    "    print(tabulate(table,headers=['Parameter','Value'],tablefmt=\"pipe\",stralign='right'))\n",
    "    \n",
    "    # Display training features\n",
    "    print('\\n\\033[4mTraining features :\\033[0m\\n')\n",
    "    print(features)\n",
    "    \n",
    "    # Display training curves\n",
    "    print('\\n\\033[4mTraining curves and predictions :\\033[0m\\n')\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    my_file = open(f'../models/CNN_runs/{model_folder}/train_loss.txt','r')\n",
    "    train_loss = my_file.readlines()\n",
    "    train_loss = [float(x.rstrip()) for x in train_loss]\n",
    "\n",
    "    my_file = open(f'../models/CNN_runs/{model_folder}/val_loss.txt','r')\n",
    "    val_loss = my_file.readlines()\n",
    "    val_loss = [float(x.rstrip()) for x in val_loss]\n",
    "    \n",
    "    fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=[22,16])\n",
    "    ax1.plot(train_loss,label='Training')\n",
    "    ax1.plot(val_loss,label='Validation')\n",
    "    ax1.set_title('Training loss'),ax1.set_ylabel('RMSE'),ax1.set_xlabel('Epochs')\n",
    "    ax1.legend()\n",
    "    ax1.grid()\n",
    "    \n",
    "    # Prediction and truth\n",
    "    ax2.plot(test.y[seq_len:],label='Truth')\n",
    "    ax2.plot(preds,label='Predictions')\n",
    "    ax2.set_title('Prediction for flight 1007'),ax2.set_ylabel('[nT]'),ax2.set_xlabel('time step')\n",
    "    ax2.legend()\n",
    "    ax2.grid()\n",
    "    \n",
    "    # Error plot\n",
    "    error = preds-np.array(test.y[seq_len:])\n",
    "\n",
    "    ax4.plot(error,label='Predictions',color='C3')\n",
    "    ax4.text(0.007,0.967,f'RMSE={RMSE:.2f}nT',fontsize=12,bbox=dict(facecolor = 'C3',alpha=0.6),transform=plt.gca().transAxes)\n",
    "    ax4.text(0.007,0.915,f'SNR={SNR:.2f}',fontsize=12,bbox=dict(facecolor = 'C3',alpha=0.6),transform=plt.gca().transAxes)\n",
    "    ax4.set_title('Prediction error for flight 1007'),ax4.set_ylabel('[nT]'),ax4.set_xlabel('time step')\n",
    "    ax4.legend(loc=1)\n",
    "    ax4.grid()\n",
    "    \n",
    "    # Error map\n",
    "    df1007 = pd.read_hdf('../data/interim/Flt_data.h5', key=f'Flt1007')\n",
    "    points = np.array([df1007['LONG'].loc[df1007.LINE==1007.06][seq_len:],df1007['LAT'].loc[df1007.LINE==1007.06][seq_len:]]).T.reshape(-1,1,2)\n",
    "    segments = np.concatenate([points[:-1],points[1:]],axis=1)\n",
    "\n",
    "    lc = LineCollection(segments,cmap=plt.get_cmap('Spectral'))\n",
    "    lc.set_array(error.reshape(-1))\n",
    "    lc.set_clim(vmin=-50,vmax=50)\n",
    "    ax3.add_collection(lc)\n",
    "\n",
    "    cbar = plt.colorbar(lc,ax=ax3,label='[nT]')\n",
    "\n",
    "    ax3.set_xlim(min(df1007['LONG'])-0.1,max(df1007['LONG'])+0.1)\n",
    "    ax3.set_ylim(min(df1007['LAT'])-0.1,max(df1007['LAT'])+0.1)\n",
    "    ax3.set_xlabel('Longitude'), ax3.set_ylabel('Latitude'), ax3.set_title('Flight 1007')\n",
    "    ax3.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d24c16b-811b-4c4e-babd-dc49b7434b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ea934d0eab4fcb894346dae25d237c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select model: ', options=('CNN_220628_1701', 'CNN_220628_083149', "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sel_model = widgets.Dropdown(\n",
    "    options     = getdirs('../models/CNN_runs'),\n",
    "    description = 'Select model: ',\n",
    "    disabled    = False)\n",
    "\n",
    "sel_model_txt = widgets.Text(\n",
    "    placeholder = 'Model Number',\n",
    "    description = 'String:'\n",
    ")\n",
    "\n",
    "\n",
    "# sel_wid_txt = widgets.interactive(visualize_model, model_folder=sel_model_txt)\n",
    "# display(sel_wid_txt)\n",
    "sel_wid = widgets.interactive(visualize_model, model_folder=sel_model)\n",
    "display(sel_wid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa3bcc-b9d2-4eb0-a213-39bbf677476b",
   "metadata": {},
   "source": [
    "# 7 - XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1b21b-4f72-4b57-baed-769301440d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
